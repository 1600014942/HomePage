<!DOCTYPE HTML>
<html lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
  <meta name="google-site-verification" content="sL6Eso6aCvLGxCvM76nGFfrCDI4uYPCDA8qYewUY8KM" />
  <meta name="author" content="Yunhe Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Yunhe Wang is a Senior Researcher of Huawei Noah's Ark Lab." />
  <meta name="keywords" content="Yunhe Wang,Yunhe,Wang Yunhe,Computer,Vision,Deep,Machine,Learning,Huawei,Noah,Peking,PKU" />

  <title>Yunhe Wang's Homepage</title>
	
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/Noah_icon.png">

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yunhe Wang</name>
              </p>
              <p>I am a principal researcher at <a href="https://www.noahlab.com.hk/">Huawei Noah's Ark Lab</a>, where I work on deep learning, model compression, and computer vision, etc.
              </p>
              <p>
                I did my PhD at school of EECS, <a href="https://www.pku.edu.cn/">Peking University</a>, where I was co-advised by <a href="https://eecs.pku.edu.cn/info/1505/6629.htm">Prof. <a href="https://dblp.org/pers/hd/x/Xu_0006:Chao">Chao Xu</a></a> and <a href="https://sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html">Prof. <a href="https://scholar.google.com.sg/citations?user=RwlJNLcAAAAJ">Dacheng Tao</a></a>. I did my bachelors at school of Science <a href="https://en.xidian.edu.cn/">Xidian University</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:yunhe.wang@huawei.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=isizOkYAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://cn.linkedin.com/in/yunhewangpku"> LinkedIn </a> &nbsp/&nbsp
                <a href="https://www.zhihu.com/people/YunheWang"> Zhi Hu </a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/YunheWang.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/YunheWang_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
	      <p>
              	6/2020, two papers have been accepted by ICML 2020.
              </p>
              <p>
              	2/2020, seven papers have been accepted by CVPR 2020. 
              </p>
              <p>
              	1/2020, one paper has been accepted by IEEE TNNLS.
              </p>
              <p>
                11/2019, three papers have been accepted by AAAI 2020.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, deep learning, model compression, and machine learning. Much of my research is about developing resource efficient neural networks for computer vision tasks (e.g. classification, detection, segmentation, and super-resolution).
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		<tr>
			<td style="padding:20px;width:25%;vertical-align:middle">
			<div class="one">
				<img src='images/GhostNet.jpg'>
				</div>
			</td>
			
			<td style="padding:20px;width:75%;vertical-align:middle">
				<a href="data/2020 CVPR GhostNet.pdf">
				<papertitle>GhostNet: More Features from Cheap Operations</papertitle>
			</a>
			<br>
			Kai Han, <strong>Yunhe Wang</strong>, Qi Tian, Jianyuan Guo, Chunjing Xu, Chang Xu
			<br>
			<em>CVPR</em>, 2020 | <a href="https://github.com/huawei-noah/ghostnet">code</a>
			<p>GhostNet beats other SOTA lightweight CNNs such as MobileNetV3 and FBNet.</p>
			</td>
		</tr>

          <tr>
			<td style="padding:20px;width:25%;vertical-align:middle">
			<div class="one">
				<img src='images/dropblock.jpg'>
			</div>
			</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2020 AAAI dropblock.pdf">
				<papertitle>Beyond Dropout: Feature Map Distortion to Regularize Deep Neural Networks</papertitle>
			</a>
			<br>
				Yehui Tang, <strong>Yunhe Wang</strong>, Yixing Xu, Boxin Shi, Chao Xu, Chunjing Xu, Chang Xu
				<br>
					<em>AAAI</em>, 2020
					<br>
						<a href="data/2020 AAAI dropblock.pdf">pdf</a> /
						<a href="data/2020 AAAI dropblock.bib">bibtex</a> 
						<p></p>
						<p>A novel regularization method for improving the performance deep neural networks.</p>
					</td>
				</tr>		
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/GAN Distillation.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2020 AAAI GAN Distillation.pdf">
			<papertitle>Distilling Portable Generative Adversarial Networks for Image Translation</papertitle>
		</a>
		<br>
			Hanting Chen, <strong>Yunhe Wang</strong>, Han Shu, Changyuan Wen, Chunjing Xu, Boxin Shi, Chao Xu, Chang Xu
			<br>
				<em>AAAI</em>, 2020
				<br>
					<a href="data/2020 AAAI GAN Distillation.pdf">pdf</a> /
					<a href="data/2020 AAAI GAN Distillation.bib">bibtex</a> 
					<p></p>
					<p>Knowledge distillation for generative adversarial networks.</p>
				</td>
			</tr>
		
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/srnas.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="https://arxiv.org/pdf/1909.11409.pdf">
			<papertitle>Efficient Residual Dense Block Search for Image Super-Resolution</papertitle>
		</a>
		<br>
			Dehua Song, Chang Xu, Xu Jia, Yiyi Chen, Chunjing Xu, <strong>Yunhe Wang</strong>
			<br>
				<em>AAAI</em>, 2020
				<br>
					<a href="data/2020 AAAI SR NAS.pdf">pdf</a> /
					<a href="data/2020 AAAI SR NAS.bib">bibtex</a> 
					<p></p>
					<p>NAS for super-resolution.</p>
				</td>
			</tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/PUcomp.jpg'>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://papers.nips.cc/paper/8525-positive-unlabeled-compression-on-the-cloud.pdf">
                <papertitle>Positive-Unlabeled Compression on the Cloud</papertitle>
              </a>
              <br>
              Yixing Xu,
              <strong>Yunhe Wang</strong>,
              Hanting Chen,
              Kai Han,
              Chunjing Xu,
              Dacheng Tao,
              Chang Xu
              <br>
              <em>NeurIPS</em>, 2019
              <br>
              	<a href="data/2019 NIPS PU Compression.pdf">pdf</a> /
              <a href="https://github.com/huawei-noah/Data-Efficient-Model-Compression/tree/master/pu_compress">code</a> /
              <a href="data/2019 NIPS PU Compression.bib">bibtex</a> / 
              <a href="http://papers.nips.cc/paper/8525-positive-unlabeled-compression-on-the-cloud-supplemental.zip">supplement</a>
              <p></p>
              <p>Using a small proportion of labeled data and massive unlabled data on the cloud to conduct the model compression task.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/DAFL.jpg'>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Data-Free_Learning_of_Student_Networks_ICCV_2019_paper.pdf">
                <papertitle>Data-Free Learning of Student Networks</papertitle>
              </a>
              <br>
              Hanting Chen,
              <strong>Yunhe Wang</strong>,
              Chang Xu,
              Zhaohui Yang,
              Chuanjian Liu,
              Boxin Shi,
              Chunjing Xu,
              Chao Xu,
              <a href="https://scholar.google.com.sg/citations?user=61b6eYkAAAAJ">Chang Xu</a>
              <br>
              <em>ICCV</em>, 2019
              <br>
              	<a href="data/2019 ICCV DAFL.pdf">pdf</a> /
              <a href="https://github.com/huawei-noah/Data-Efficient-Model-Compression/tree/master/DAFL">code</a> /
              <a href="data/2019 ICCV DAFL.bib">bibtex</a> 
              <p></p>
              <p>The first work for distilling student networks without any training data by exploiting a generator.</p>
            </td>
          </tr>
     
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/GAN Pruning.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Shu_Co-Evolutionary_Compression_for_Unpaired_Image_Translation_ICCV_2019_paper.pdf">
				<papertitle>Co-Evolutionary Compression for Unpaired Image Translation</papertitle>
			</a>
			<br>
				Han Shu, <strong>Yunhe Wang</strong>, Xu Jia, Kai Han, Hanting Chen, Chunjing Xu, <a href="https://scholar.google.com.sg/citations?user=61b6eYkAAAAJ">Chang Xu</a>, Chang Xu
				<br>
					<em>ICCV</em>, 2019
					<br>
						<a href="data/2019 ICCV Co-Evolution Pruning.pdf">pdf</a> /
						<a href="https://github.com/huawei-noah/GAN-pruning">code</a> /
						<a href="data/2019 ICCV Co-Evolution Pruning.bib">bibtex</a> 
						<p></p>
						<p>Compressing CycleGAN using evolution algorithm.</p>
					</td>
				</tr>

          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/SeacrhingBNN.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/NeurArch/Shen_Searching_for_Accurate_Binary_Neural_Architectures_ICCVW_2019_paper.pdf">
				<papertitle>Searching for Accurate Binary Neural Architectures</papertitle>
			</a>
			<br>
				Mingzhu Shen, Kai Han, Chunjing Xu, <strong>Yunhe Wang</strong>
				<br>
					<em>ICCV Neural Architectures Workshop</em>, 2019
					<br>
						<a href="data/2019 ICCVw Bianry Search.pdf">pdf</a> /
						<a href="data/2019 ICCVw Bianry Search.bib">bibtex</a> 
						<p></p>
						<p>Searching for binary networks which can achieve the performance of full-precision models.</p>
					</td>
				</tr>
			
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/legonet.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="http://proceedings.mlr.press/v97/yang19c/yang19c.pdf">
				<papertitle>LegoNet: Efficient Convolutional Neural Networks with Lego Filters</papertitle>
			</a>
			<br>
				Zhaohui Yang, <strong>Yunhe Wang</strong>, Hanting Chen, Chuanjian Liu, Boxin Shi, Chao Xu, Chunjing Xu, Chang Xu
				<br>
					<em>ICML</em>, 2019
					<br>
						<a href="data/2019 ICML LegoNet.pdf">pdf</a> /
						<a href="data/2019 ICML LegoNet.bib">bibtex</a> /
						<a href="https://github.com/huawei-noah/LegoNet">code</a> 
						<p></p>
						<p>A split-transform merge strategy for An efficient convolution.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/InstanceSparsity.JPG'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="https://www.ijcai.org/proceedings/2019/0416.pdf">
				<papertitle>Learning Instance-wise Sparsity for Accelerating Deep Models</papertitle>
			</a>
			<br>
		        Chuanjian Liu, <strong>Yunhe Wang</strong>, Kai Han, Chunjing Xu, Chang Xu
				<br>
					<em>IJCAI</em>, 2019
					<br>
						<a href="data/2019 IJCAI Instance Sparsity.pdf">pdf</a> /
						<a href="data/2019 IJCAI Instance Sparsity.bib">bibtex</a> 
						<p></p>
						<p>An instance-wise feature pruning method during online inference.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/attributepooling.JPG'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="https://www.ijcai.org/proceedings/2019/0341.pdf">
				<papertitle>Attribute Aware Pooling for Pedestrian Attribute Recognition</papertitle>
			</a>
			<br>
				Kai Han, <strong>Yunhe Wang</strong>, Han Shu, Chuanjian Liu, Chunjing Xu, Chang Xu
				<br>
					<em>IJCAI</em>, 2019
					<br>
						<a href="data/2019 IJCAI Attribute Recognition.pdf">pdf</a> /
						<a href="data/2019 IJCAI Attribute Recognition.bib">bibtex</a> 
						<p></p>
						<p>Attribute Aware Pooling for multi-attribute classification on the pedestrian attribute recognition problem.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/craftentropy.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="https://www.ijcai.org/proceedings/2019/0311.pdf">
				<papertitle>Crafting Efficient Neural Graph of Large Entropy</papertitle>
			</a>
			<br>
				Minjing Dong, Hanting Chen, <strong>Yunhe Wang</strong>, Chang Xu
				<br>
					<em>IJCAI</em>, 2019
					<br>
						<a href="data/2019 IJCAI Graph Pruning.pdf">pdf</a> /
						<a href="data/2019 IJCAI Graph Pruning.bib">bibtex</a> 
						<p></p>
						<p>Pruning neural networks under the supervision of graph entropy.</p>
					</td>
				</tr>
	
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/featuredistillation.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8682926">
				<papertitle>Low Resolution Visual Recognition via Deep Feature Distillation</papertitle>
			</a>
			<br>
				Mingjian Zhu, Kai Han, Chao Zhang, Jinlong Lin, <strong>Yunhe Wang</strong>
				<br>
					<em>ICASSP</em>, 2019
					<br>
						<a href="data/2019 ICASSP LR Distillation.pdf">pdf</a> /
						<a href="data/2019 ICASSP LR Distillation.bib">bibtex</a> 
						<p></p>
						<p>Exploiting feature distillation to learn well-performed models for recognizing low-resolution objects.</p>
					</td>
				</tr>

          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/versertile.JPG'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="https://papers.nips.cc/paper/7433-learning-versatile-filters-for-efficient-convolutional-neural-networks.pdf">
				<papertitle>Learning Versatile Filters for Efficient Convolutional Neural Networks</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Chang Xu, Chunjing Xu, Chao Xu, Dacheng Tao
				<br>
					<em>NeuriPS</em>, 2018
					<br>
						<a href="data/2018 NIPS Versatile Filter.pdf">pdf</a> /
						<a href="https://github.com/huawei-noah/Versatile-Filters">code</a> /
						<a href="data/2018 NIPS Versatile Filter.bib">bibtex</a> / 
						<a href="https://papers.nips.cc/paper/7433-learning-versatile-filters-for-efficient-convolutional-neural-networks-supplemental.zip">supplement</a>
						<p></p>
						<p>Versatile filters to construct efficient convolutional neural network..</p>
					</td>
				</tr>

          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/evolution.JPG'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="https://dl.acm.org/doi/pdf/10.1145/3219819.3219970?download=true">
				<papertitle>Towards Evolutionary Compression</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Chang Xu, Jiayan Qiu, Chao Xu, Dacheng Tao
				<br>
					<em>SIGKDD</em>, 2018
					<br>
						<a href="data/2018 KDD GA pruning.pdf">pdf</a> /
						<a href="data/2018 KDD GA pruning.bib">bibtex</a> 
						<p></p>
						<p>Using evolutionary algorithm to compress and accelerate CNNs.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/autoencoder.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="http://150.162.46.34:8080/icassp2018/ICASSP18_USB/pdfs/0002941.pdf">
				<papertitle>Autoencoder Inspired Unsupervised Feature Selection</papertitle>
			</a>
			<br>
				Kai Han, <strong>Yunhe Wang</strong>, Chao Zhang, Chao Li, Chao Xu
				<br>
					<em>ICASSP</em>, 2018
					<br>
						<a href="data/2018 ICASSP Feature Selector.pdf">pdf</a> /
						<a href="data/2018 ICASSP Feature Selector.bib">bibtex</a> 
						<p></p>
						<p>AutoEncoder Feature Selector (AEFS) for unsupervised feature selection.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/adversarial.JPG'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="https://pdfs.semanticscholar.org/f37a/8472b00f4a00a91abb41e5ab764d5a5076a8.pdf">
				<papertitle>Adversarial Learning of Portable Student Networks</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao
				<br>
					<em>AAAI</em>, 2018
					<br>
						<a href="data/2018 AAAI Adversarial Distillation.pdf">pdf</a> /
						<a href="data/2018 AAAI Adversarial Distillation.bib">bibtex</a> 
						<p></p>
						<p>Knowledge distillation by introducing a discriminator.</p>
					</td>
				</tr>

          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/dct.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8413170">
				<papertitle>Packing Convolutional Neural Networks in the Frequency Domain</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao
				<br>
					<em>IEEE TPAMI</em>, 2018
					<br>
						<a href="data/2018 PAMI CNNpack.pdf">pdf</a> /
						<a href="data/2018 PAMI CNNpack.bib">bibtex</a> 
						<p></p>
						<p>Compressing and speeding up CNNs in the frequency domain.</p>
					</td>
				</tr>

          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/redcnn.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="http://proceedings.mlr.press/v70/wang17m/wang17m.pdf">
				<papertitle>Beyond Filters: Compact Feature Map for Portable Deep Model</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao
				<br>
					<em>ICML</em>, 2017
					<br>
						<a href="data/2017 ICML Beyond Filters.pdf">pdf</a> /
						<a href="https://github.com/YunheWang/RedCNN">code</a>/
						<a href="data/2017 ICML Beyond Filters.bib">bibtex</a> /
						<a href="http://proceedings.mlr.press/v70/wang17m/wang17m-supp.zip">supplement</a>
						<p></p>
						<p>Eliminate the redundancy of the feature maps in CNNs.</p>
					</td>
				</tr>

          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/RPCA.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14291/14473">
				<papertitle>Beyond RPCA: Flattening Complex Noise in the Frequency Domain</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao
				<br>
					<em>AAAI</em>, 2017
					<br>
						<a href="data/2017 AAAI Beyond RPCA.pdf">pdf</a> /
						<a href="data/2017 AAAI Beyond RPCA.bib">bibtex</a> 
						<p></p>
						<p>Image de-noise in the frequency domain.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/privileged.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="https://www.ijcai.org/proceedings/2017/0466.pdf">
				<papertitle>Privileged Multi-Label Learning</papertitle>
			</a>
			<br>
				Shan You, Chang Xu, <strong>Yunhe Wang</strong>, Chao Xu, Dacheng Tao.
				<br>
					<em>IJCAI</em>, 2017
					<br>
						<a href="data/2017 IJCAI Privileged.pdf">pdf</a> /
						<a href="data/2017 IJCAI Privileged.bib">bibtex</a> 
						<p></p>
						<p>Exploit the relationship between labels in multi-label learning problems.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/DCTrecover.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7872479">
				<papertitle>DCT Regularized Extreme Visual Recovery</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Chang Xu, Shan You, Chao Xu, Dacheng Tao
				<br>
					<em>IEEE TIP</em>, 2017
					<br>
						<a href="data/2017 TIP DCT norm.pdf">pdf</a> /
						<a href="data/2017 TIP DCT norm.bib">bibtex</a> 
						<p></p>
						<p>Extreme visual recovery based on discrete cosine transform.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/CNNpack.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="https://papers.nips.cc/paper/6390-cnnpack-packing-convolutional-neural-networks-in-the-frequency-domain.pdf">
				<papertitle>CNNpack: Packing Convolutional Neural Networks in the Frequency Domain</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Chang Xu, Shan You, Dacheng Tao, Chao Xu
				<br>
					<em>NIPS</em>, 2016
					<br>
						<a href="data/2016 NIPS CNNpack.pdf">pdf</a> /
						<a href="data/2016 NIPS CNNpack.bib">bibtex</a> /
						<a href="https://papers.nips.cc/paper/6390-cnnpack-packing-convolutional-neural-networks-in-the-frequency-domain-supplemental.zip">supplement</a>
						<p></p>
						<p>Transforming convolutional filters and feature maps into frequency domain to compress and accelerate CNNs.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/dift.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7508985">
				<papertitle>DCT inspired feature transform for image retrieval and reconstruction</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Miaojing Shi, Shan You, Chao Xu
				<br>
					<em>IEEE TIP</em>, 2016
					<br>
						<a href="data/2016 TIP DCT feature.pdf">pdf</a> /
						<a href="data/2016 TIP DCT feature.bib">bibtex</a> 
						<p></p>
						<p>A new DCT inspired feature transform for representing images in computer vision tasks.</p>
					</td>
				</tr>


        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ijcai.png">
            </td>
            <td width="75%" valign="center">
              <a href="https://www.ijcai20.org/">Senior PC Member, IJCAI 2020</a>
              <br>
              <br>
              <a href="https://www.ijcai19.org/program-committee.html">Senior PC Member, IJCAI 2019</a>
            </td>
          </tr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
		<tr>
			<td>
				<heading>Awards</heading>
			</td>
		</tr>
	</tbody></table>
<table width="100%" align="center" border="0" cellpadding="20"><tbody>
		<tr>
			<td style="padding:20px;width:25%;vertical-align:middle">
				<img src="images/google.png">
				</td>
				<td width="75%" valign="center">
					<a href="https://research.google/outreach/phd-fellowship/recipients/?category=2017">Google PhD Fellowship, 2017</a>
						</td>
					</tr>
				
						<tr>
					<td style="padding:20px;width:25%;vertical-align:middle">
						<img src="images/baidu.png">
						</td>
						<td width="75%" valign="center">
									<a href="http://scholarship.baidu.com/">Baidu Scholarship, 2017</a>
								</td>
							</tr>

          </tbody></table>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
            <td>
            <br>
            <p align="right"><font size="2">
			<a href="https://info.flagcounter.com/HwGN"><img src="https://s11.flagcounter.com/count2/HwGN/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_0/pageviews_0/flags_0/percent_0/" alt="Flag Counter" border="0"></a>
            </p>  
            <p align="right"><font size="2">
            Thanks to <a href="https://jonbarron.info/"><strong>Jon Barron</strong></a> for sharing his code.
            </font>
            </p>
            </td>
            </tr>
          </tbody></table>
      </td>
    </tr>
  </table>

</body>

</html>
