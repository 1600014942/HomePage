<!DOCTYPE HTML>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<meta name="keywords" content="Yunhe Wang, YunheWang, wangyunhe, Yunhe, Wang Yunhe, Computer, Vision, Deep, Machine, Learning, Huawei, Noah, Peking, PKU" />

	<meta name="author" content="Yunhe Wang">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="Yunhe Wang is a Senior Researcher of Huawei Noah's Ark Lab." />

	<script data-ad-client="ca-pub-4826497670839648" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<meta name="google-site-verification" content="sL6Eso6aCvLGxCvM76nGFfrCDI4uYPCDA8qYewUY8KM" />

	<title>Yunhe Wang's Homepage</title>

	<link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" type="image/png" href="images/panda.png">

</head>

<body>

<div id="menu" >
	<ul style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
		<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody><tr>
			<td style="text-align: left;">
			<li><a href="#">Home</a></li>
			</td>
			<td style="text-align: right;">
			<li><a href="#projects">Projects</a></li>
			<li><a href="#publications">Publications</a></li>
			<li><a href="#talks">Talks</a></li>
			</td>
	    </tr></tbody></table>
	</ul>
</div>

  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yunhe Wang</name>
              </p>
              <p>
              	I am a senior researcher at <a href="https://www.noahlab.com.hk/">Huawei Noah's Ark Lab</a>, Beijing, where I work on deep learning, model compression, and computer vision, etc.
              </p>
              <p>
                I did my PhD at school of EECS, <a href="https://www.pku.edu.cn/">Peking University</a>, where I was co-advised by <a href="https://eecs.pku.edu.cn/info/1505/6629.htm">Prof. <a href="https://dblp.org/pers/hd/x/Xu_0006:Chao">Chao Xu</a></a> and <a href="https://sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html">Prof. <a href="https://scholar.google.com.sg/citations?user=RwlJNLcAAAAJ">Dacheng Tao</a></a>. I did my bachelors at school of science, <a href="https://en.xidian.edu.cn/">Xidian University</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:yunhe.wang@huawei.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=isizOkYAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://cn.linkedin.com/in/yunhewangpku"> LinkedIn </a> &nbsp/&nbsp
                <a href="https://dblp.org/pers/w/Wang:Yunhe.html"> DBLP </a> &nbsp/&nbsp
                <a href="https://www.zhihu.com/people/YunheWang"> Zhi Hu </a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/YunheWang_circle.jpg" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
	      	<p><li> 06/2020, two papers have been accepted by <a href="https://icml.cc/Conferences/2020/AcceptedPapersInitial">ICML 2020</a>.</p>
            <p><li> 02/2020, seven papers have been accepted by <a href="http://openaccess.thecvf.com/menu.py">CVPR 2020</a>.</p>
            <p><li> 01/2020, one paper has been accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE TNNLS</a>.</p>
            <p><li> 11/2019, three papers have been accepted by <a href="https://aaai.org/Conferences/AAAI-20/wp-content/uploads/2020/01/AAAI-20-Accepted-Paper-List.pdf">AAAI 2020</a>.</p>
            </td>
            </tr>
        </tbody></table>

        <a name="projects"></a>
   	    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		    <tr>
			<td style="padding:20px;width:100%;vertical-align:middle">
			<heading>Recent Projects</heading>
			<p><em>
                Actually, model compression is a kind of technique for developing portable deep neural networks with lower memory and computation costs. I have done several projects in Huawei including some smartphones' applications in 2019 and 2020 (e.g. Mate 30 and Honor V30). Currently, I am leading the AdderNet project, which aims to develop a series of deep learning models using only additions (<a href="https://www.reddit.com/r/MachineLearning/comments/ekw2s1/r_addernet_do_we_really_need_multiplications_in/">Discussions on Reddit</a>).
            </em></p>
			</td>
			</tr>
			</tbody></table>

		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
			<tr>
			<td style="padding:20px;width:25%;vertical-align:middle">
			<div class="one">
				<img style="width:100%;max-width:100%" src="images/HDC2020-small.gif">
			</div>
			</td>
			<td style="padding:20px;width:75%;vertical-align:middle">
				<papertitle>AI on Ascend: Real-Time Video Style Transfer</papertitle>
				<br>
				<a href="https://www.huaweicloud.com/intl/en-us/HDC.Cloud.html"><em>Huawei Developer Conference</em> (HDC) 2020</a> | <a href="https://developer.huaweicloud.com/exhibition/Atlas_neural_style.html">Online Demo</a>
				<p>
				This project aims to develop a video style transfer system on the <strong>Huawei Atlas 200 DK AI developer Kit</strong>. The latency of the original model for processing one image is about <span style="color:red">630ms</span>. After accelerating it using our method, the lantency now is about <span style="color:red">40ms</span>. 
				</p>	
			</td>
			</tr>
	    </tbody></table>

	    <a name="publications"></a>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		    <tr>
			<td style="padding:20px;width:100%;vertical-align:middle">
			<heading>Research</heading>

			<p>
                <em>I'm interested in <strong>efficient</strong> models for computer vision including classification, detection, segmentation, super-resolution, etc.</em>
            </p>

			<p><strong>Conference papers: </strong></p>

			<ol>

			<p>
			<li><papertitle>Learning Binary Neurons with Noisy Supervision</papertitle>
			<br>
			Kai Han, <strong>Yunhe Wang</strong>, Yixing Xu, Chunjing Xu, Enhua Wu, Chang Xu
			<br>
			<em>ICML</em> 2020 | to appear
			</p>

			<p>
			<li><papertitle>Neural Architecture Search in a Proxy Validation Loss Landscape</papertitle>
			<br>
			Yanxi Li, Minjing Dong, <strong>Yunhe Wang</strong>, Chang Xu
			<br>
			<em>ICML</em> 2020 | to appear
			</p>

			<p>
			<li><papertitle>On Positive-Unlabeled Classification in GAN</papertitle>
			<br>
			Tianyu Guo, Chang Xu, Jiajun Huang, <strong>Yunhe Wang</strong>, Boxin Shi, Chao Xu, Dacheng Tao
			<br>
			<em>CVPR</em> 2020 | <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Guo_On_Positive-Unlabeled_Classification_in_GAN_CVPR_2020_paper.pdf"> paper</a>
			</p>

			<p>
			<li><papertitle>CARS: Continuous Evolution for Efficient Neural Architecture Search</papertitle>
			<br>
			Zhaohui Yang, <strong>Yunhe Wang</strong>, Xinghao Chen, Boxin Shi, Chao Xu, Chunjing Xu, Qi Tian, Chang Xu
			<br>
			<em>CVPR</em> 2020 | <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_CARS_Continuous_Evolution_for_Efficient_Neural_Architecture_Search_CVPR_2020_paper.pdf"> paper</a> | <a href="https://github.com/huawei-noah/CARS">code</a> 
			</p>

			<p>
			<li><papertitle>AdderNet: Do we really need multiplications in deep learning?</papertitle>
			<br>
			Hanting Chen*, <strong>Yunhe Wang</strong>*, Chunjing Xu, Boxin Shi, Chao Xu, Qi Tian, Chang Xu
			<br>
			<em>CVPR</em> 2020 (* equal contribution) | <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_AdderNet_Do_We_Really_Need_Multiplications_in_Deep_Learning_CVPR_2020_paper.pdf"> paper</a> | <a href="https://github.com/huawei-noah/AdderNet"> code </a> 
			<br><span style="color:red"> Oral Presentation</span>
			<br>
			</p>

			<p>
			<li><papertitle>A Semi-Supervised Assessor of Neural Architectures</papertitle>
			<br>
			Yehui Tang, <strong>Yunhe Wang</strong>, Yixing Xu, Hanting Chen, Boxin Shi, Chao Xu, Chunjing Xu, Qi Tian, Chang Xu
			<br>
			<em>CVPR</em> 2020 | <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Tang_A_Semi-Supervised_Assessor_of_Neural_Architectures_CVPR_2020_paper.pdf"> paper</a> 
			</p>

			<p>
			<li><papertitle>Hit-Detector: Hierarchical trinity architecture search for object detection</papertitle>
			<br>
			Jianyuan Guo, Kai Han, <strong>Yunhe Wang</strong>, Chao Zhang, Zhaohui Yang, Han Wu, Xinghao Chen, Chang Xu
			<br>
			<em>CVPR</em> 2020 | <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Guo_Hit-Detector_Hierarchical_Trinity_Architecture_Search_for_Object_Detection_CVPR_2020_paper.pdf"> paper</a> | <a href="https://github.com/ggjy/HitDet.pytorch">code</a>
			</p>

			<p>
			<li><papertitle>Frequency Domain Compact 3D Convolutional Neural Networks</papertitle>
			<br>
			Hanting Chen, <strong>Yunhe Wang</strong>, Han Shu, Yehui Tang, Chunjing Xu, Boxin Shi, Chao Xu, Qi Tian, Chang Xu 
			<br>
			<em>CVPR</em> 2020 | <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_Frequency_Domain_Compact_3D_Convolutional_Neural_Networks_CVPR_2020_paper.pdf"> paper</a>
			</p>

			<li><papertitle>GhostNet: More Features from Cheap Operations</papertitle>			
			<br>
			Kai Han, <strong>Yunhe Wang</strong>, Qi Tian, Jianyuan Guo, Chunjing Xu, Chang Xu
			<br>
			<em>CVPR</em> 2020 | <a href="data/2020 CVPR GhostNet.pdf"> paper </a> | <a href="https://github.com/huawei-noah/ghostnet">code</a> 
			</p>
			
			<p>
			<li><papertitle>Beyond Dropout: Feature Map Distortion to Regularize Deep Neural Networks</papertitle>	
			<br>
			Yehui Tang, <strong>Yunhe Wang</strong>, Yixing Xu, Boxin Shi, Chao Xu, Chunjing Xu, Chang Xu
			<br>
			<em>AAAI</em> 2020 |<a href="data/2020 AAAI dropblock.pdf"> paper </a> | <a href="https://github.com/huawei-noah/disout">code</a>
			</p>

			<p>
			<li><papertitle>DropNAS: Grouped Operation Dropout for Differentiable Architecture Search</papertitle>
			<br>
			Weijun Hong, Guilin Li, Weinan Zhang, Ruiming Tang, <strong>Yunhe Wang</strong>, Zhenguo Li, Yong Yu
			<br>
			<em>IJCAI</em> 2020 | to appear
			</p>

			<p>
			<li><papertitle>Distilling Portable Generative Adversarial Networks for Image Translation</papertitle>
			<br>
			Hanting Chen, <strong>Yunhe Wang</strong>, Han Shu, Changyuan Wen, Chunjing Xu, Boxin Shi, Chao Xu, Chang Xu
			<br>
			<em>AAAI</em> 2020 |<a href="data/2020 AAAI GAN Distillation.pdf"> paper </a>
			</p>

			<p>
			<li><papertitle>Efficient Residual Dense Block Search for Image Super-Resolution</papertitle>
			<br>
			Dehua Song, Chang Xu, Xu Jia, Yiyi Chen, Chunjing Xu, <strong>Yunhe Wang</strong>
			<br>
			<em>AAAI</em>, 2020 |<a href="data/2020 AAAI SR NAS.pdf"> paper </a> | <a href="https://github.com/huawei-noah/vega">code</a>
			</p>

			<p>
			<li><papertitle>Positive-Unlabeled Compression on the Cloud</papertitle>
			<br>
			Yixing Xu, <strong>Yunhe Wang</strong>, Hanting Chen, Kai Han, Chunjing Xu, Dacheng Tao, Chang Xu
			<br>
			<em>NeurIPS</em> 2019 |  <a href="data/2019 NIPS PU Compression.pdf">paper | <a href="https://github.com/huawei-noah/Data-Efficient-Model-Compression/tree/master/pu_compress">code</a> | <a href="http://papers.nips.cc/paper/8525-positive-unlabeled-compression-on-the-cloud-supplemental.zip">supplement</a>
			</p>

			<p>
			<li><papertitle>Data-Free Learning of Student Networks</papertitle>
			<br>
			Hanting Chen,<strong>Yunhe Wang</strong>, Chang Xu,Zhaohui Yang,Chuanjian Liu,Boxin Shi,Chunjing Xu,Chao Xu,Chang Xu
			<br>
			<em>ICCV</em> 2019 | <a href="data/2019 ICCV DAFL.pdf">paper</a> | <a href="https://github.com/huawei-noah/Data-Efficient-Model-Compression/tree/master/DAFL">code</a>
			</p>

			<p>
			<li><papertitle>Co-Evolutionary Compression for Unpaired Image Translation</papertitle>
			<br>
			Han Shu, <strong>Yunhe Wang</strong>, Xu Jia, Kai Han, Hanting Chen, Chunjing Xu, Chang Xu, Chang Xu 
			<br>
			<em>ICCV</em> 2019 | <a href="data/2019 ICCV Co-Evolution Pruning.pdf"> paper | <a href="https://github.com/huawei-noah/GAN-pruning">code</a> 
			</p>

			<p>
			<li><papertitle>Searching for Accurate Binary Neural Architectures</papertitle>
			<br>
			Mingzhu Shen, Kai Han, Chunjing Xu, <strong>Yunhe Wang</strong>
			<br>
			<em>ICCV Neural Architectures Workshop</em> 2019 | <a href="data/2019 ICCVw Bianry Search.pdf"> paper </a>
			</p>

			<p>
			<li><papertitle>LegoNet: Efficient Convolutional Neural Networks with Lego Filters</papertitle>
			<br>
			Zhaohui Yang, <strong>Yunhe Wang</strong>, Hanting Chen, Chuanjian Liu, Boxin Shi, Chao Xu, Chunjing Xu, Chang Xu
			<br>
			<em>ICML</em> 2019 | <a href="data/2019 ICML LegoNet.pdf">paper</a> | <a href="https://github.com/huawei-noah/LegoNet">code</a> 
			</p>

			<p>
			<li><papertitle>Learning Instance-wise Sparsity for Accelerating Deep Models</papertitle>
			<br>
			Chuanjian Liu, <strong>Yunhe Wang</strong>, Kai Han, Chunjing Xu, Chang Xu 
			<br>
			<em>IJCAI</em> 2019 | <a href="data/2019 IJCAI Instance Sparsity.pdf">paper</a>
			</p>

			<p>
			<li><papertitle>Attribute Aware Pooling for Pedestrian Attribute Recognition</papertitle>
			<br>
			Kai Han, <strong>Yunhe Wang</strong>, Han Shu, Chuanjian Liu, Chunjing Xu, Chang Xu
			<br>
			<em>IJCAI</em> 2019 | <a href="https://www.ijcai.org/proceedings/2019/0341.pdf">paper</a>
			</p>

			<p>
			<li><papertitle>Crafting Efficient Neural Graph of Large Entropy</papertitle>
			<br>
			Minjing Dong, Hanting Chen, <strong>Yunhe Wang</strong>, Chang Xu
			<br>
			<em>IJCAI</em> 2019 | <a href="data/2019 IJCAI Graph Pruning.pdf">paper</a>
			</p>

			<p>
			<li><papertitle>Low Resolution Visual Recognition via Deep Feature Distillation</papertitle>
			<br>
			Mingjian Zhu, Kai Han, Chao Zhang, Jinlong Lin, <strong>Yunhe Wang</strong>
			<br>
			<em>ICASSP</em> 2019 | <a href="data/2019 ICASSP LR Distillation.pdf">paper</a> 
			</p>

			<p>
			<li><papertitle>Learning Versatile Filters for Efficient Convolutional Neural Networks</papertitle>
			<br>
			<strong>Yunhe Wang</strong>, Chang Xu, Chunjing Xu, Chao Xu, Dacheng Tao 
			<br>
			<em>NeurIPS</em> 2018 | <a href="data/2018 NIPS Versatile Filter.pdf">paper</a> | <a href="https://github.com/huawei-noah/Versatile-Filters">code</a> | <a href="https://papers.nips.cc/paper/7433-learning-versatile-filters-for-efficient-convolutional-neural-networks-supplemental.zip">supplement</a> 
			</p>

			<p>
			<li><papertitle>Towards Evolutionary Compression</papertitle>
			<br>
			<strong>Yunhe Wang</strong>, Chang Xu, Jiayan Qiu, Chao Xu, Dacheng Tao 
			<br>
			<em>SIGKDD</em> 2018 | <a href="data/2018 KDD GA pruning.pdf">paper</a> 
			</p>

			<p>
			<li><papertitle>Autoencoder Inspired Unsupervised Feature Selection</papertitle>
			<br>
			Kai Han, <strong>Yunhe Wang</strong>, Chao Zhang, Chao Li, Chao Xu 
			<br>
			<em>ICASSP</em> 2018 | <a href="data/2018 ICASSP Feature Selector.pdf">paper</a> | <a href="https://github.com/NoahLuffy/AEFS">code</a> 
			</p>

			<p>
			<li><papertitle>Adversarial Learning of Portable Student Networks</papertitle>
			<br>
			<strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao 
			<br>
			<em>AAAI</em> 2018 | <a href="data/2018 AAAI Adversarial Distillation.pdf">paper</a> 
			</p>

			<p>
			<li><papertitle>Beyond Filters: Compact Feature Map for Portable Deep Model</papertitle>
			<br>
			<strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao 
			<br>
			<em>ICML</em> 2017 | <a href="data/2017 ICML Beyond Filters.pdf">paper</a> | <a href="https://github.com/YunheWang/RedCNN">code</a> | <a href="http://proceedings.mlr.press/v70/wang17m/wang17m-supp.zip">supplement</a>
			</p>

			<p>
			<li><papertitle>Beyond RPCA: Flattening Complex Noise in the Frequency Domain</papertitle>
			<br>
			<strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao 
			<br>
			<em>AAAI</em> 2017 | <a href="data/2017 AAAI Beyond RPCA.pdf">paper</a>
			</p>

			<p>
			<li><papertitle>Privileged Multi-Label Learning</papertitle>
			<br>
			Shan You, Chang Xu, <strong>Yunhe Wang</strong>, Chao Xu, Dacheng Tao 
			<br>
			<em>IJCAI</em> 2017 | <a href="data/2017 IJCAI Privileged.pdf">paper</a> 
			</p>

			<p>
			<li><papertitle>CNNpack: Packing Convolutional Neural Networks in the Frequency Domain</papertitle>
			<br>
			<strong>Yunhe Wang</strong>, Chang Xu, Shan You, Chao Xu, Dacheng Tao
			<br>
			<em>NeurIPS</em> 2016 | <a href="data/2016 NIPS CNNpack.pdf">paper</a> | <a href="https://papers.nips.cc/paper/6390-cnnpack-packing-convolutional-neural-networks-in-the-frequency-domain-supplemental.zip">supplement</a> 
			</p>

			</ol>

			<p><strong>Journal papers: </strong></p>

			<ol>

			<p>
			<li><papertitle>Learning student networks via feature embedding</papertitle>
			<br>
			Hanting Chen, <strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao
			<br>
			<em>IEEE TNNLS</em> 2020 | <a href="https://arxiv.org/pdf/1812.06597">paper</a>
			</p>

			<p>
			<li><papertitle>Packing Convolutional Neural Networks in the Frequency Domain</papertitle>
			<br>
			<strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao
			<br>
			<em>IEEE TPAMI</em> 2018 | <a href="data/2018 PAMI CNNpack.pdf">paper</a>
			</p>

			<p>
			<li><papertitle>DCT Regularized Extreme Visual Recovery</papertitle>
			<br>
			<strong>Yunhe Wang</strong>, Chang Xu, Shan You, Chao Xu, Dacheng Tao
			<br>
			<em>IEEE TIP</em> 2017 | <a href="data/2017 TIP DCT norm.pdf">paper</a> 
			</p>

			<p>
			<li><papertitle>DCT inspired feature transform for image retrieval and reconstruction</papertitle>
			<br>
			<strong>Yunhe Wang</strong>, Miaojing Shi, Shan You, Chao Xu
			<br>
			<em>IEEE TIP</em> 2016 | <a href="data/2016 TIP DCT feature.pdf">paper</a>
			</p>

			</ol>

			</td>
		    </tr>
        </tbody></table>

        <a name="talks"></a>
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Talks</heading>
              <p><li>06/2020, "<a href="http://valser.org/webinar/slide/slides/20200603/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9-%E5%B7%A5%E4%B8%9A%E7%95%8C%E5%92%8C%E5%AD%A6%E6%9C%AF%E7%95%8C%E7%9A%84%E5%B7%AE%E5%BC%82.pdf"><em>AI on the Edge - Discussion on the Gap Between Industry and Academia</em></a>" at <a href="http://valser.org/" style="color:gray"><u>VALSE</u></a> Webinar.  </p>
              <p><li>05/2020, "<a href="https://www.bilibili.com/video/av925692420/"> <em>Edge AI: Progress and Future Directions</em></a>" at <a href="https://www.qbitai.com/" style="color:gray"> <u>QbitAI</u>  </a>. </p>
              </td>
          </tr>
        </tbody></table>

        <a name="service"></a>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Service</heading>
              <p><li> Senior Program Committee Members of <a href="https://www.ijcai20.org/">IJCAI 2020</a> and <a href="https://www.ijcai19.org/program-committee.html">IJCAI 2019</a>.</p>
              <p><li> Journal Reviewers of IJCV, IEEE T-IP, IEEE T-NNLS, IEEE TMM, IEEE T-KDE, etc.</p>
			  <p><li> Program Committee Members of NeurIPS 2020, ICML 2020, ECCV 2020, CVPR 2020, ICLR 2020, AAAI 2020, ICCV 2019, CVPR 2019, ICLR 2019, AAAI 2019, IJCAI 2018, AAAI 2018, NeurIPS 2018, etc.</p>
            </td>
          </tr>
        </tbody></table>

        <a name="awards"></a>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Awards</heading>
			<p><li> 2017, <a href="https://research.google/outreach/phd-fellowship/recipients/?category=2017">Google PhD Fellowship</a></p>
			<p><li> 2017, <a href="http://scholarship.baidu.com/">Baidu Scholarship</a></p>
			<p><li> 2017, President's PhD Scholarship, <em>Peking University</em></p>
			<p><li> 2017, National Scholarship for Graduate Students</p>
			<p><li> 2016, National Scholarship for Graduate Students</p>
			</td>
            </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">	
			<p align="right"><font size="2">
			<a href="https://info.flagcounter.com/HwGN"><img src="https://s11.flagcounter.com/count2/HwGN/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_0/pageviews_0/flags_0/percent_0/" alt="Flag Counter" border="0"></a>
			<br>
			Thanks to <a href="https://jonbarron.info/"><strong>Jon Barron</strong></a> for sharing his code.
			<br>
			Thanks to <a href="https://icons8.com/icon/16093/panda"><strong>Icons8</strong></a> for the icon.</p>
			</td>
            </tr>
        </tbody></table>

</body>

</html>
