<!DOCTYPE HTML>
<html lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
  <meta name="google-site-verification" content="sL6Eso6aCvLGxCvM76nGFfrCDI4uYPCDA8qYewUY8KM" />
  <meta name="author" content="Yunhe Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Yunhe Wang is a Senior Researcher of Huawei Noah's Ark Lab." />
  <meta name="keywords" content="Yunhe Wang,Yunhe,Wang Yunhe,Computer,Vision,Deep,Machine,Learning,Huawei,Noah,Peking,PKU" />

  <title>Yunhe Wang's Homepage</title>
	
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/Noah_icon.png">

</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yunhe Wang</name>
              </p>
              <p>I am a principal researcher at <a href="https://www.noahlab.com.hk/">Huawei Noah's Ark Lab</a>, where I work on deep learning, model compression, and computer vision, etc.
              </p>
              <p>
                I did my PhD at school of EECS, <a href="https://www.pku.edu.cn/">Peking University</a>, where I was co-advised by <a href="https://eecs.pku.edu.cn/info/1505/6629.htm">Prof. <a href="https://dblp.org/pers/hd/x/Xu_0006:Chao">Chao Xu</a></a> and <a href="https://sydney.edu.au/engineering/about/our-people/academic-staff/dacheng-tao.html">Prof. <a href="https://scholar.google.com.sg/citations?user=RwlJNLcAAAAJ">Dacheng Tao</a></a>. I did my bachelors at school of Science <a href="https://en.xidian.edu.cn/">Xidian University</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:yunhe.wang@huawei.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=isizOkYAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://cn.linkedin.com/in/yunhewangpku"> LinkedIn </a> &nbsp/&nbsp
                <a href="https://www.zhihu.com/people/YunheWang"> Zhi Hu </a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/YunheWang.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/YunheWang_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
	      <p>
              	<li> 6/2020, two papers have been accepted by ICML 2020. 
              </p>
              <p>
              	<li> 2/2020, seven papers have been accepted by CVPR 2020. 
              </p>
              <p>
              	<li> 1/2020, one paper has been accepted by IEEE TNNLS. 
              </p>
              <p>
                <li> 11/2019, three papers have been accepted by AAAI 2020. 
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, deep learning, model compression, and machine learning. Much of my research is about developing resource efficient neural networks for computer vision tasks (e.g. classification, detection, segmentation, and super-resolution).
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		<tr>
			<td style="padding:20px;width:25%;vertical-align:middle">
			<div class="one">
				<img src='images/GhostNet.jpg'>
				</div>
			</td>
			
			<td style="padding:20px;width:75%;vertical-align:middle">
				<a href="data/2020 CVPR GhostNet.pdf">
				<papertitle>GhostNet: More Features from Cheap Operations</papertitle>
			</a>
			<br>
			Kai Han, <strong>Yunhe Wang</strong>, Qi Tian, Jianyuan Guo, Chunjing Xu, Chang Xu
			<br>
			<em>CVPR</em>, 2020 | <a href="https://github.com/huawei-noah/ghostnet">code</a>
			<p>GhostNet beats other SOTA lightweight CNNs such as MobileNetV3 and FBNet.</p>
			</td>
		</tr>

          <tr>
			<td style="padding:20px;width:25%;vertical-align:middle">
			<div class="one">
				<img src='images/dropblock.jpg'>
			</div>
			</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2020 AAAI dropblock.pdf">
				<papertitle>Beyond Dropout: Feature Map Distortion to Regularize Deep Neural Networks</papertitle>
			</a>
			<br>
				Yehui Tang, <strong>Yunhe Wang</strong>, Yixing Xu, Boxin Shi, Chao Xu, Chunjing Xu, Chang Xu
				<br>
					<em>AAAI</em>, 2020 | <a href="https://github.com/huawei-noah/disout">code</a>
						<p>A novel regularization method for improving the performance deep neural networks.</p>
					</td>
				</tr>		
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/GAN Distillation.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2020 AAAI GAN Distillation.pdf">
			<papertitle>Distilling Portable Generative Adversarial Networks for Image Translation</papertitle>
		</a>
		<br>
			Hanting Chen, <strong>Yunhe Wang</strong>, Han Shu, Changyuan Wen, Chunjing Xu, Boxin Shi, Chao Xu, Chang Xu
			<br>
				<em>AAAI</em>, 2020 
				<p>Knowledge distillation for generative adversarial networks.</p>
				</td>
			</tr>
		
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/srnas.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2020 AAAI SR NAS.pdf">
			<papertitle>Efficient Residual Dense Block Search for Image Super-Resolution</papertitle>
		</a>
		<br>
			Dehua Song, Chang Xu, Xu Jia, Yiyi Chen, Chunjing Xu, <strong>Yunhe Wang</strong>
			<br>
				<em>AAAI</em>, 2020 | <a href="https://github.com/huawei-noah/vega">code</a>
					<p>The state-of-the-art NAS method for single image super-resolution.</p>
				</td>
			</tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/PUcomp.jpg'>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/2019 NIPS PU Compression.pdf">
                <papertitle>Positive-Unlabeled Compression on the Cloud</papertitle>
              </a>
              <br>
              Yixing Xu,
              <strong>Yunhe Wang</strong>,
              Hanting Chen,
              Kai Han,
              Chunjing Xu,
              Dacheng Tao,
              Chang Xu
              <br>
              <em>NeurIPS</em>, 2019 | <a href="https://github.com/huawei-noah/Data-Efficient-Model-Compression/tree/master/pu_compress">code</a> |    
              <a href="http://papers.nips.cc/paper/8525-positive-unlabeled-compression-on-the-cloud-supplemental.zip">supplement</a>
              <p>Using a small proportion of labeled data and massive unlabled data on the cloud to conduct the model compression task.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/DAFL.jpg'>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/2019 ICCV DAFL.pdf">
                <papertitle>Data-Free Learning of Student Networks</papertitle>
              </a>
              <br>
              Hanting Chen,
              <strong>Yunhe Wang</strong>,
              Chang Xu,
              Zhaohui Yang,
              Chuanjian Liu,
              Boxin Shi,
              Chunjing Xu,
              Chao Xu,
              <a href="https://scholar.google.com.sg/citations?user=61b6eYkAAAAJ">Chang Xu</a>
              <br>
              <em>ICCV</em>, 2019 |  <a href="https://github.com/huawei-noah/Data-Efficient-Model-Compression/tree/master/DAFL">code</a> /
              <p>The first work for distilling student networks without any training data by exploiting a generator.</p>
            </td>
          </tr>
     
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/GAN Pruning.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2019 ICCV Co-Evolution Pruning.pdf">
				<papertitle>Co-Evolutionary Compression for Unpaired Image Translation</papertitle>
			</a>
			<br>
				Han Shu, <strong>Yunhe Wang</strong>, Xu Jia, Kai Han, Hanting Chen, Chunjing Xu, <a href="https://scholar.google.com.sg/citations?user=61b6eYkAAAAJ">Chang Xu</a>, Chang Xu
				<br>
					<em>ICCV</em>, 2019 | <a href="https://github.com/huawei-noah/GAN-pruning">code</a> 
						<p>The first paper for compressing and accelerating GANs, especially CycleGAN. This paper explores a co-evolutionary approach for removing redundant filters iteratively.</p>
					</td>
				</tr>

          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/SeacrhingBNN.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2019 ICCVw Bianry Search.pdf">
				<papertitle>Searching for Accurate Binary Neural Architectures</papertitle>
			</a>
			<br>
				Mingzhu Shen, Kai Han, Chunjing Xu, <strong>Yunhe Wang</strong>
				<br>
					<em>ICCV Neural Architectures Workshop</em>, 2019
					<p> The first work for searching binary neural architectures, which can achieve the comparable performance to that of full-precision models.</p>
					</td>
				</tr>
			
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/legonet.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2019 ICML LegoNet.pdf">
				<papertitle>LegoNet: Efficient Convolutional Neural Networks with Lego Filters</papertitle>
			</a>
			<br>
				Zhaohui Yang, <strong>Yunhe Wang</strong>, Hanting Chen, Chuanjian Liu, Boxin Shi, Chao Xu, Chunjing Xu, Chang Xu
				<br>
					<em>ICML</em>, 2019
					<br>
						<a href="data/2019 ICML LegoNet.pdf">pdf</a> /
						<a href="data/2019 ICML LegoNet.bib">bibtex</a> /
						<a href="https://github.com/huawei-noah/LegoNet">code</a> 
						<p></p>
						<p>A novel convolution operation, namely Lego filter is developed for constructing efficient deep neural networks.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/InstanceSparsity.JPG'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2019 IJCAI Instance Sparsity.pdf">
				<papertitle>Learning Instance-wise Sparsity for Accelerating Deep Models</papertitle>
			</a>
			<br>
		        Chuanjian Liu, <strong>Yunhe Wang</strong>, Kai Han, Chunjing Xu, Chang Xu
				<br>
					<em>IJCAI</em>, 2019
					<p>An instance-wise feature pruning method during online inference.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/attributepooling.JPG'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="https://www.ijcai.org/proceedings/2019/0341.pdf">
				<papertitle>Attribute Aware Pooling for Pedestrian Attribute Recognition</papertitle>
			</a>
			<br>
				Kai Han, <strong>Yunhe Wang</strong>, Han Shu, Chuanjian Liu, Chunjing Xu, Chang Xu
				<br>
					<em>IJCAI</em>, 2019
					<p>Attribute Aware Pooling for multi-attribute classification on the pedestrian attribute recognition problem.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/craftentropy.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2019 IJCAI Graph Pruning.pdf">
				<papertitle>Crafting Efficient Neural Graph of Large Entropy</papertitle>
			</a>
			<br>
				Minjing Dong, Hanting Chen, <strong>Yunhe Wang</strong>, Chang Xu
				<br>
					<em>IJCAI</em>, 2019
					<p>Pruning neural networks under the supervision of graph entropy.</p>
					</td>
				</tr>
	
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/featuredistillation.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2019 ICASSP LR Distillation.pdf">
				<papertitle>Low Resolution Visual Recognition via Deep Feature Distillation</papertitle>
			</a>
			<br>
				Mingjian Zhu, Kai Han, Chao Zhang, Jinlong Lin, <strong>Yunhe Wang</strong>
				<br>
					<em>ICASSP</em>, 2019
						<p>Exploiting feature distillation to learn well-performed models for recognizing low-resolution objects.</p>
					</td>
				</tr>

          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/versertile.JPG'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2018 NIPS Versatile Filter.pdf">
				<papertitle>Learning Versatile Filters for Efficient Convolutional Neural Networks</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Chang Xu, Chunjing Xu, Chao Xu, Dacheng Tao
				<br>
					<em>NeurIPS</em>, 2018 | <a href="https://github.com/huawei-noah/Versatile-Filters">code</a> | <a href="https://papers.nips.cc/paper/7433-learning-versatile-filters-for-efficient-convolutional-neural-networks-supplemental.zip">supplement</a>
				
						<p>A series fo versatile filters will be utilized for producing portable convolutional neural networks with comparable performance.</p>
					</td>
				</tr>

          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/evolution.JPG'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2018 KDD GA pruning.pdf">
				<papertitle>Towards Evolutionary Compression</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Chang Xu, Jiayan Qiu, Chao Xu, Dacheng Tao
				<br>
					<em>SIGKDD</em>, 2018
						<p>The first work that automatically removes redundant filters in pre-trained CNNs using the genetic algorithm.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/autoencoder.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2018 ICASSP Feature Selector.pdf">
				<papertitle>Autoencoder Inspired Unsupervised Feature Selection</papertitle>
			</a>
			<br>
				Kai Han, <strong>Yunhe Wang</strong>, Chao Zhang, Chao Li, Chao Xu
				<br>
				<em>ICASSP</em>, 2018 | <a href="https://github.com/NoahLuffy/AEFS">code</a>
				<p>This work utilizes an auto-encoder to conduct the unsupervised feature selection task.</p>
				</td>
			</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/adversarial.JPG'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
		<a href="data/2018 AAAI Adversarial Distillation.pdf">
			<papertitle>Adversarial Learning of Portable Student Networks</papertitle>
		</a>
		<br>
		<strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao
		<br>
		<em>AAAI</em>, 2018
		<p>Knowledge distillation by introducing a discriminator to help the training of a portable student network.</p>
		</td>
	</tr>

          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/dct.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2018 PAMI CNNpack.pdf">
				<papertitle>Packing Convolutional Neural Networks in the Frequency Domain</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao
				<br>
					<em>IEEE TPAMI</em>, 2018
				<p>Compressing and speeding up CNNs in the frequency domain.</p>
			</td>
		</tr>

          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/redcnn.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2017 ICML Beyond Filters.pdf">
				<papertitle>Beyond Filters: Compact Feature Map for Portable Deep Model</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao
				<br>
					<em>ICML</em>, 2017 | <a href="https://github.com/YunheWang/RedCNN">code</a> | <a href="http://proceedings.mlr.press/v70/wang17m/wang17m-supp.zip">supplement
						<p>Eliminate the redundancy of feature maps and then reconstruct new filters to compact CNN architectures.</p>
					</td>
				</tr>

          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/RPCA.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2017 AAAI Beyond RPCA.pdf">
				<papertitle>Beyond RPCA: Flattening Complex Noise in the Frequency Domain</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Chang Xu, Chao Xu, Dacheng Tao
				<br>
					<em>AAAI</em>, 2017
						<p>This paper studies the RPCA problem in the frequency domain for better handling the noise.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/privileged.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2017 IJCAI Privileged.pdf">
				<papertitle>Privileged Multi-Label Learning</papertitle>
			</a>
			<br>
				Shan You, Chang Xu, <strong>Yunhe Wang</strong>, Chao Xu, Dacheng Tao.
				<br>
					<em>IJCAI</em>, 2017
						<p>Exploiting the relationship between labels in multi-label learning problems.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/DCTrecover.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2017 TIP DCT norm.pdf">
				<papertitle>DCT Regularized Extreme Visual Recovery</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Chang Xu, Shan You, Chao Xu, Dacheng Tao
				<br>
					<em>IEEE TIP</em>, 2017
						<p>Extreme visual recovery based on discrete cosine transform.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/CNNpack.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2016 NIPS CNNpack.pdf">
				<papertitle>CNNpack: Packing Convolutional Neural Networks in the Frequency Domain</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Chang Xu, Shan You, Dacheng Tao, Chao Xu
				<br>
					<em>NIPS</em>, 2016
					<br>
						<a href="data/2016 NIPS CNNpack.pdf">pdf</a> | <a href="https://papers.nips.cc/paper/6390-cnnpack-packing-convolutional-neural-networks-in-the-frequency-domain-supplemental.zip">supplement</a>
						<p>This work present to convert all pre-trained filters into the DCT frequency domain to obtain higher sparsity. In addition, a novel frequency domain accelerating approach is also developed for avoiding the decompression.</p>
					</td>
				</tr>
			
          <tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<img src='images/dift.jpg'>
			</div>
		</td>
		<td style="padding:20px;width:75%;vertical-align:middle">
			<a href="data/2016 TIP DCT feature.pdf">
				<papertitle>DCT inspired feature transform for image retrieval and reconstruction</papertitle>
			</a>
			<br>
				<strong>Yunhe Wang</strong>, Miaojing Shi, Shan You, Chao Xu
				<br>
					<em>IEEE TIP</em>, 2016
						<p>A new DCT inspired feature transform for extracting feature representations of natural images, which can be utilized to replace the conventional SIFT.</p>
					</td>
				</tr>


        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Service</heading>
              <p>
              	<li> Senior PC of <a href="https://www.ijcai20.org/">IJCAI 2020</a>, <a href="https://www.ijcai19.org/program-committee.html">IJCAI 2019</a>
              </p>
              <p>
				<li> Journal Reviewer of IJCV, IEEE T-NNLS, IEEE T-IP, IEEE T-KDE, etc. 
			  </p>
			  <p>
				<li> Program Committee Members of NeurIPS 2020, ICML 2020, ECCV 2020, CVPR 2020, ICLR 2020, AAAI 2020, ICCV 2019, CVPR 2019, ICLR 2019, AAAI 2019, IJCAI 2018, AAAI 2018, NeurIPS 2018, etc.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Awards</heading>
            </td>
          	</tr>

            <td style="padding:20px;width:25%;vertical-align:middle">
			<p><li> 2017, <a href="https://research.google/outreach/phd-fellowship/recipients/?category=2017">Google PhD Fellowship, 2017</a></p>
			<p><li> 2017, <a href="http://scholarship.baidu.com/">Baidu Scholarship, 2017</a></p>
			<p><li> 2017, President's PhD Scholarship, <em>Peking University</em>, 2017</p>
			<p><li> 2017, National Scholarship for Graduate Students</p>
			<p><li>	2017, Top Ten Students with Academic Research Honor, <em>School of EECS, Peking University</em></p>
			<p><li> 2016, National Scholarship for Graduate Students</p>
			</td>

			<td style="padding:20px;width:75%;vertical-align:middle">
			<p align="right"><font size="2">
			<a href="https://info.flagcounter.com/HwGN"><img src="https://s11.flagcounter.com/count2/HwGN/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_0/pageviews_0/flags_0/percent_0/" alt="Flag Counter" border="0"></a>
			Thanks to <a href="https://jonbarron.info/"><strong>Jon Barron</strong></a> for sharing his code.
			</td>
            
        </tbody></table>

</body>

</html>
